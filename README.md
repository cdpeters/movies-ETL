# **Movie Data ETL Pipeline**

## **Overview of Project**
The goal of this project is to construct an Extract-Transform-Load (ETL) data pipeline using movie and movie rating data from both Wikipedia and Kaggle. The focus is restricted to just the creation of the pipeline yielding cleaned and stored data; any analysis of the data is outside the scope of the project.

The task was completed using four jupyter notebooks that build on each other, successively adding each stage of the ETL process. The final objective was to have one script that automates the entire process, starting with the extract stage and ending with the loading of data into a PostgreSQL database. Additionally, the transform stage was broken into four segments, one for the necessary cleaning operations of each dataset and a final one for the merge operations.

Script breakdown:
    - ETL_function_test.ipynb - Extract stage
    - ETL_clean_wiki_movies.ipynb - Adds Wikipedia movie data transformations
    - ETL_clean_kaggle_data.ipynb - Adds Kaggle metadata and ratings data transformations
    - ETL_create_database.ipynb - Adds Load stage

## **Extract**

## **Transform**
### **Wikipedia Movie Data**

### **Kaggle Movie Metadata**

### **Kaggle Movie Rating Data**

### **Merge the Data**

## **Load**

## **Summary**


<div align="center">
    <img src="" alt="" />
</div>
